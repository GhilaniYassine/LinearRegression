{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTAN_sHKDR1D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=0.3\n",
        "b=0.7\n",
        "## creating a tensor which\n",
        "start = 0\n",
        "end = 1\n",
        "step =0.05\n",
        "X = torch.arange(start ,end ,step).unsqueeze(dim=1) ## YOU JUST FILL THE TENSOR X WITH ALL OF THE POSSIBLE VALUES THAAT EXIST BETEWEN 0 AND 1 WITH STEP = 0.05\n",
        "Y = a*X +b ## BUT RIGHT HERE YOU FILL THE Y TENSOR WITH THE ALL VALUES BETEWEN 0 AND 1 BUT USING THE LINEAR REGRESSION FORMULA Y = a*X +b\n",
        "## X AND Y  both of em are  tensors and they the same dim\n",
        "#####Y.ndim == X.ndim ### YOU SEE RIGHT HERE MAAN\n"
      ],
      "metadata": {
        "id": "If8fgdczDYES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"SO 100% OF THE DATASET WILL BE DIVIDED INTO TO SPLITS\n",
        "1\\\\ IS THE TRAIN SET OR WE COULD CALL IT THE TRAINSPLIT WHICH WILL BE 80% of THE DATA THAT WE HAVE INITIALLY\n",
        "2\\\\ IS THE TEST SET OR THE ALSO CALLED THE TESTSPLIT WHICH WILL 20% OF THEE DATA THAAT WE HADD\n",
        "\"\"\"\n",
        "\n",
        "### THIS IS THE MOST IMPORTANT THING IN ML\n",
        "train_split = int(0.8*len(X))\n",
        "x_train = X[:train_split]\n",
        "x_test = X[train_split: ]\n",
        "y_train =Y[:train_split]\n",
        "y_test =Y[train_split: ]\n",
        "###len(x_train),len(x_test ),len(y_train),len(y_test)\n"
      ],
      "metadata": {
        "id": "CmS4VRoKDYH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_predictions(train_data = x_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = x_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = None ):\n",
        "  plt.figure(figsize=(10,7))\n",
        "  # THE TRAINING  DATA IN BLUE\n",
        "  plt.scatter(train_data ,train_labels ,c='b',s=4,label ='TRAINING DATA')\n",
        "  ## PLOT TESTING DATA IN GREEN\n",
        "  plt.scatter(test_data ,test_labels ,c='g',s=4,label = 'TESTING DATA')\n",
        "  ## ARE THERE PREDICTIONS IF YES PLOT IT\n",
        "  if predictions is not None :\n",
        "     # plot predictions in what color :::::::red\n",
        "     plt.scatter(test_data , predictions ,c='r',s=4,label = 'PREDICTIONS' )\n",
        "\n",
        "  ## show the legends\n",
        "  plt.legend(prop={\"size\":4})\n"
      ],
      "metadata": {
        "id": "Y-5Vghy6GASf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "x4v7xwRXS3qh",
        "outputId": "314b5115-9ffb-4455-9201-198174ec5188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### LET'S BUILD OUR FIRST MODEL\n",
        "class LinearRegressionM(nn.Module): ## subclass\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.a = nn.Parameter(torch.randn(1,requires_grad=True,\n",
        "                                      dtype=torch.float))\n",
        "    self.b = nn.Parameter(torch.randn(1,requires_grad = True,\n",
        "                                      dtype= torch.float))\n",
        "  def forward(self , x:torch.tensor)->torch.tensor: ## x is the input data\n",
        "      return self.a*x +self.b ## formule\n",
        "\n"
      ],
      "metadata": {
        "id": "HS3rKzA3S3nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### HERE WHAT THE MODEL WILL DO DILL START WITH 2 RANDOM VALUES OF A AND B THAN ADJUST THEM THROUGHT WHAT\n",
        "## THROUGH LOOKING AT THE TRAIN_DATA\n",
        "## creat  a random seed\n",
        "torch.manual_seed(42)\n",
        "## creat an instance of the model (this is a subclass of nn)\n",
        "model_0 = LinearRegressionM()\n",
        "list(model_0.parameters\n",
        "     ())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hnmydxoS3k2",
        "outputId": "63bd9ea6-cac7-4813-eb4b-4ccd28a17822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ANOTHER WAY TO PRINT  THE PARAMETERS MORE CLEAR\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiHSbsDxS3ir",
        "outputId": "8a3ababc-59c8-43ec-d650-ad78c6c74ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('a', tensor([0.3367])), ('b', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQnLL4I-SkKk",
        "outputId": "f2632e61-4526-482f-c8e0-bd749e918279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9400],\n",
              "        [0.9550],\n",
              "        [0.9700],\n",
              "        [0.9850]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##making predictions using ''''''' inference_mode()'''\n",
        "##to check our model predictive power let's see how it will predict y_test based on x_test\n",
        "## when pass data in our model  it's going to run it through the forword methode\n",
        "with torch.inference_mode ():\n",
        "  y_preds =model_0(x_test)\n",
        "y_preds\n",
        "## you can also do something simillar with torch.no_grad() however torch.inference_mode()is preferrd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehjOWV3IjNef",
        "outputId": "09a683c5-d378-41c9-f9ad-858ddb50d50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3982],\n",
              "        [0.4150],\n",
              "        [0.4318],\n",
              "        [0.4487]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions = y_preds) ##\" the model is too stupid\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "Qh98xnqxlHp3",
        "outputId": "51b014ba-cc26-4d4e-9a68-f63e08d88d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAJGCAYAAACTJvC6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzcklEQVR4nO3dfXRcdZ348U86JQkICWghLTVLeVDQA1K3QC3qceKJWxe2E0TXoiwPVVDYipLqUSqFuoDUFZZTDeVBBOGsaEFFMi61CDVRcbtWi90FhbJQoEVJoLomWGkDk/n9MT9Sah/olCaTfPN6nTPne+b23sxneq7gm3szU1UsFosBAACQkDGVHgAAAGB3EzoAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkJyxlR5gZ/T398fvf//72GeffaKqqqrS4wAAABVSLBbjueeeiwMPPDDGjNn+dZsRETq///3vo7GxsdJjAAAAw8S6devi9a9//Xb/fESEzj777BMRpTdTV1dX4WkAAIBK6e3tjcbGxoFG2J4RETov3a5WV1cXdXV10d/fH319fRWeauhVV1fv8PIcAACMFq/0Ky0jInRerr+/P5588snYuHFjpUcZcrW1tXHQQQeJHQAAeAUjLnT6+vpi48aNMX78+Nhzzz0rPc6Qef7556Orqyv6+vqitra20uMAAMCwNuJC5yV77rmn/8MPAABs04gNnW3J5yM6OiKamiJyuR3v+8ILL8SiRYtiyZIlccIJJ8Tdd98dEydOjMsuuyzGjx8fJ598clx55ZVxyCGHxLx58+Kwww6LX/3qV3H11VfHvHnzorm5OV588cX4zne+E+9617vi+OOPj3vvvTeOPfbYuPPOO2PvvfeO173udXHmmWdGRMQXvvCFqK+vj02bNsXkyZPjve99b1x//fVRKBTiqKOOinvuuSceeeSRmDFjRhx00EHx7W9/OxYtWjT4f2kAAJCgZEInn49oaYnIZCIWLoxob99x7Oyxxx5x/vnnx/r162Py5Mlx5JFHxsaNG6OnpyceeeSRuPDCC+OHP/xhzJ49e+CY17zmNbF69eotfs7+++8fDzzwQBx77LEREXH77bfHF7/4xW2+5nnnnRdjx46NuXPnxvTp0+OFF16IYrEYb3/726OxsTHuvffeOPXUU+OrX/1qnHDCCfHYY4/FoYce+qr/bgAAYLQp+7faf/rTn8aMGTPiwAMPjKqqqrjzzjtf8ZjOzs7427/926ipqYnDDjssbr755l0Ydcc6OkqRUyiU1s7O8o7/wQ9+ENdff32MGzculi5dGj/72c/iF7/4RfT39w/sc+aZZ8Y3vvGNrY79yEc+EjfeeGNEbP70hx/84AexYMGC7b5eZ2dnPPnkk/HUU0/FsmXLBrb/+c9/jl/+8pfx8MMPx/e+973y3gQAABARuxA6GzZsiKOPPnqnb6t6/PHH48QTT4ympqZYtWpVnH/++XHWWWfF3XffXfawO9LUtDlyCoWIbLa842fMmBFf+cpX4rLLLot99903zj///Dj77LPjnnvuGdhnjz32iLe+9a3R1dW1xbFveMMbBj4F7gMf+EBccsklsXbt2qiurt5iv7a2tvjSl74U2Ww2fvzjH8cVV1wR//qv/xo/+clPBva5/fbb45JLLolPf/rTsWHDhi1CCwAA2DlVxWKxuMsHV1XF97///TjppJO2u8/nPve5uOuuu+LBBx8c2HbKKafEn/70p1i6dOlOvU5vb2/U19dHT09PVFdXx+OPPx4HH3zwVh9GkM+XruRks6/8OzojzcaNG7f7vgEAYLR4eRvU1dVtd79B/x2d5cuXR3Nz8xbbpk+fHueff/52j9m0aVNs2rRp4Hlvb+9OvVYul17gAAAA5Rv0b57s6uqKhoaGLbY1NDREb29vPP/889s8ZsGCBVFfXz/waGxsHOwxAQCAhAx66OyKuXPnRk9Pz8Bj3bp1lR4JAAAYQQb91rXx48dHd3f3Ftu6u7ujrq4u9txzz20eU1NTEzU1NWW/Vn51Pjoe74img5sid/iO72Hb1vfoTJ8+Pd7//vfHwoULY8KECXHUUUfFE088Ed///vfj7/7u76KpqSlWrlwZTz31VOy9997xmc98JubNmxcf//jH42tf+1rst99+kclk4lOf+lRERNx8883x2GOPRV1dXbz+9a+PD33oQ3HbbbfFY489FieeeGJ0dHTEkiVL4n3ve1+ceOKJcd5558Wdd9458MltAADArhn00Jk2bVosWbJki2333HNPTJs2bbe+Tn51PloWt0SmKhMLf7Ew2k9p32Hs/PX36DzyyCMREVFbWxvPPPNMvOc974l3vetdMX369Hj66afjk5/8ZDz11FMDx//lL3+JP/7xjxERcdNNN8VFF1201aesRUScccYZcdhhh8XcuXPjQx/6UHR3d8f48ePjkEMOiaOPPjrWr18f5557blx77bUxf/786OjoiHe/+9279e8GAABGm7JvXfvzn/8cq1atilWrVkVE6eOjV61aFWvXro2I0m1np59++sD+55xzTqxZsyY++9nPxsMPPxzXXHNN3H777dHa2rp73sH/1/F4R2SqMlEoFiJTlYnOJzrLOv7kk0+O888/P/bff/+48cYbo7a2docznnvuuXHNNdcMPK+qqoqf/OQnMXfu3O0es2bNmvif//mf+P3vfx933HHHwPZisRj/9V//FT/96U/jRz/6UVlzAwAAWyv7is6vfvWraGpqGng+Z86ciChdubj55pvj6aefHoieiIiDDz447rrrrmhtbY2vfOUr8frXvz6+/vWvx/Tp03fD+Js1HdwUC3+xcCB2spOyZR1/xx13xIMPPhgzZsyI22+/PaqqquLQQw/d7v777bdf7L333rFx48b4yEc+EpdeemkccMABW91yd8stt0RdXV285S1vicWLF0dbW1vsueeeMW/evIF9fvzjH8eZZ54ZTU1NceWVV0ZPT0/U19eXNT8AALDZq/oenaGy09+jszofnU90RnZS9hV/R2ek8T06AAAwjL5HZyjlDs8lFzgAAED5huXHSwMAALwaaYVOPh/R2lpaAQCAUSudW9fy+YiWlohMJmLhwoj29ojcjm9j+8IXvhB777133HrrrTFt2rTo6+uLyy67LK677rqoq6uLMWPGREtLS8ydOzfe9ra3xfPPPx9z586NefPmxWc/+9m44oor4rWvfW2MGzcu/vCHPwx8J88+++wTBx10UPT398cvf/nLeOGFF+If/uEf4sEHH4xf/epXcfXVV8e8efPi1FNPjWuvvTb+5m/+Jj784Q/HgQceODR/VwAAkLh0QqejoxQ5hUJp7ex8xdCJiDj//PPj1ltvjZNPPjk2btwYPT09A39WU1MTVVVV0dzcHGeddVbceuut8Zvf/CYiIr75zW/GOeecExMnThzYf/369XH++edHZ2dnvPjii9HZ2RmXX355RER8/vOfjze+8Y3xmte8JlavXh0REX/4wx9ir732ive85z0iBwCAYSm/Oh8dj3dE08FNI+r34dO5da2paXPkFAoR2exOHbZw4cL4xCc+ET/4wQ/i+uuvj3HjxkVExCc/+ck499xzd3hsVVXVDv98Wx9od+aZZ8Y3vvGNiIh4xzveEZ/+9Kfjhz/8YbS3t+/UvAAAMFTyq/PRsrgl2la0RcvilsivHjm/IpLOFZ1crnS7WmdnKXJ24mpOROmKzn333RcHHXRQHHLIIbFw4cLIZDLx1a9+NcaMGRN///d/H/fee2/8+c9/jueffz5OPfXUiIg49dRT44orrojXve51MWHChDjllFO2+tnvete74otf/GK88MILcfLJJ8eDDz4Ye+yxR7z1rW+Ne+65J/77v/877r333njmmWeiubl5N/5lAADAq9fxeMfA91RmqjLR+UTniLmqk9T36KTM9+gAADDUXrqi81LstJ/SXvHQSf57dJ5//vlKjzCkRtv7BQCg8nKH56L9lPbofKIzspOyFY+ccoy40Kmuro7a2tro6uqq9ChDrra2Nqqrqys9BgAAo0ju8NyICpyXjLjQGTNmTBx00EHR19dX6VGGXHV1dYwZk87nRwAAwGAZcaETUYodv6cCAABsj8sDAABAcoQOAACQHKEDAAAkR+gAAADJEToAADBM5Ffno3Vpa+RX5ys9yogndAAAYBjIr85Hy+KWaFvRFi2LW8TOqyR0AABgGOh4vCMyVZkoFAuRqcpE5xOdlR5pRBM6AAAwDDQd3DQQOYViIbKTspUeaUQbkV8YCgAAqckdnov2U9qj84nOyE7KRu7wXKVHGtGqisVisdJDvJLe3t6or6+Pnp6eqKurq/Q4AABAhexsG7h1DQAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AAEal/Op8tC5tjfzqfKVHYRAIHQAARp386ny0LG6JthVt0bK4RewkSOgAADDqdDzeEZmqTBSKhchUZaLzic5Kj8RuJnQAABh1mg5uGoicQrEQ2UnZSo/Ebja20gMAAMBQyx2ei/ZT2qPzic7ITspG7vBcpUdiN6sqFovFSg/xSnp7e6O+vj56enqirq6u0uMAAAAVsrNt4NY1AAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAYNDlV+ejdWlr5FfnKz0Ko4TQAQBgUOVX56NlcUu0rWiLlsUtYochIXQAABhUHY93RKYqE4ViITJVmeh8orPSIzEKCB0AAAZV08FNA5FTKBYiOylb6ZEYBcZWegAAANKWOzwX7ae0R+cTnZGdlI3c4blKj8QoUFUsFouVHuKV9Pb2Rn19ffT09ERdXV2lxwEAACpkZ9vArWsAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAkJp+PaG0trTBaCR0AgITk8xEtLRFtbaVV7DBaCR0AgIR0dERkMhGFQmnt7Kz0RFAZQgcAICFNTZsjp1CIyGYrPRFUxthKDwAAwO6Ty0W0t5eu5GSzpecwGgkdAIDE5HICB9y6BgAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAK9CPh/R2lpageFD6AAA7KJ8PqKlJaKtrbSKHRg+hA4AwC7q6IjIZCIKhdLa2VnpiYCXCB0AgF3U1LQ5cgqFiGy20hMBLxlb6QEAAEaqXC6ivb10JSebLT0HhgehAwDwKuRyAgeGI7euAQAAydml0Fm0aFFMmjQpamtrY+rUqbFixYrt7vvCCy/EJZdcEoceemjU1tbG0UcfHUuXLt3lgQEAAF5J2aFz2223xZw5c2L+/Plx//33x9FHHx3Tp0+PZ555Zpv7z5s3L66//vpoa2uL3/72t3HOOefE+973vvj1r3/9qocHAADYlqpisVgs54CpU6fGscceG1dffXVERPT390djY2Ocd955ccEFF2y1/4EHHhgXXnhhzJ49e2Db+9///thzzz3jm9/85k69Zm9vb9TX10dPT0/U1dWVMy4AAJCQnW2Dsq7o9PX1xcqVK6O5uXnzDxgzJpqbm2P58uXbPGbTpk1RW1u7xbY999wz7rvvvu2+zqZNm6K3t3eLBwAAwM4qK3TWr18fhUIhGhoattje0NAQXV1d2zxm+vTpcdVVV8X//u//Rn9/f9xzzz1xxx13xNNPP73d11mwYEHU19cPPBobG8sZEwAAGOUG/VPXvvKVr8Qb3vCGOOKII6K6ujo+8YlPxKxZs2LMmO2/9Ny5c6Onp2fgsW7dusEeEwAASEhZoTNu3LjIZDLR3d29xfbu7u4YP378No/Zf//9484774wNGzbEk08+GQ8//HDsvffeccghh2z3dWpqaqKurm6LBwBAPh/R2lpaAXakrNCprq6OKVOmxLJlywa29ff3x7Jly2LatGk7PLa2tjYmTpwYL774Ynzve9+LlpaWXZsYABiV8vmIlpaItrbSKnaAHSn71rU5c+bEDTfcELfccks89NBDce6558aGDRti1qxZERFx+umnx9y5cwf2/8UvfhF33HFHrFmzJn72s5/Fe9/73ujv74/Pfvazu+9dAADJ6+iIyGQiCoXS2tlZ6YmA4WxsuQfMnDkznn322bj44oujq6srJk+eHEuXLh34gIK1a9du8fs3GzdujHnz5sWaNWti7733jhNOOCH+/d//Pfbdd9/d9iYAgPQ1NUUsXLg5drLZSk8EDGdlf49OJfgeHQAgonS7WmdnKXJyuUpPA1TCzrZB2Vd0AAAqJZcTOMDOGfSPlwYAABhqQgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQC2KZ+PaG0trQAjjdABALaSz0e0tES0tZVWsQOMNEIHANhKR0dEJhNRKJTWzs5KTwRQHqEDAGylqWlz5BQKEdlspScCKM/YSg8AAAw/uVxEe3vpSk42W3oOMJIIHQBgm3I5gQOMXG5dAwAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAhoF8PqK1tbQC8OoJHQCosHw+oqUloq2ttIodgFdP6ABAhXV0RGQyEYVCae3srPREACOf0AGACmtq2hw5hUJENlvpiQBGvrGVHgAARrtcLqK9vXQlJ5stPQfg1RE6ADAM5HICB2B3cusaAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgCMOvl8RGtraQUgTUIHgFEln49oaYloayutYgcgTUIHgFGloyMik4koFEprZ2elJwJgMAgdAEaVpqbNkVMoRGSzlZ4IgMEwttIDAMBQyuUi2ttLV3Ky2dJzANIjdAAYdXI5gQOQOreuAQAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4Agyqfj2htLa0AMFSEDgCDJp+PaGmJaGsrrWIHgKEidAAYNB0dEZlMRKFQWjs7Kz0RAKOF0AFg0DQ1bY6cQiEim630RACMFmMrPQAA6crlItrbS1dystnScwAYCkIHgEGVywkcAIaeW9cAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAUhIPh/R2lpaAWA0EzoAicjnI1paItraSqvYAWA0EzoAiejoiMhkIgqF0trZWemJAKByhA5AIpqaNkdOoRCRzVZ6IgConLGVHgCA3SOXi2hvL13JyWZLzwFgtBI6AAnJ5QQOAES4dQ0AAEiQ0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AHZRPh/R2lpaAYDhRegA7IJ8PqKlJaKtrbSKHQAYXnYpdBYtWhSTJk2K2tramDp1aqxYsWKH+y9cuDAOP/zw2HPPPaOxsTFaW1tj48aNuzQwwHDQ0RGRyUQUCqW1s7PSEwEAL1d26Nx2220xZ86cmD9/ftx///1x9NFHx/Tp0+OZZ57Z5v7f+ta34oILLoj58+fHQw89FDfeeGPcdttt8fnPf/5VDw9QKU1NmyOnUIjIZis9EQDwclXFYrFYzgFTp06NY489Nq6++uqIiOjv74/GxsY477zz4oILLthq/0984hPx0EMPxbJlywa2ffrTn45f/OIXcd999+3Ua/b29kZ9fX309PREXV1dOeMCDJp8vnQlJ5uNyOUqPQ0AjA472wZlXdHp6+uLlStXRnNz8+YfMGZMNDc3x/Lly7d5zPHHHx8rV64cuL1tzZo1sWTJkjjhhBO2+zqbNm2K3t7eLR4Aw00uF3HVVSIHAIajseXsvH79+igUCtHQ0LDF9oaGhnj44Ye3ecyHP/zhWL9+fbzjHe+IYrEYL774Ypxzzjk7vHVtwYIF8S//8i/ljAYAADBg0D91rbOzMy6//PK45ppr4v7774877rgj7rrrrrj00ku3e8zcuXOjp6dn4LFu3brBHhMAAEhIWVd0xo0bF5lMJrq7u7fY3t3dHePHj9/mMRdddFGcdtppcdZZZ0VExFFHHRUbNmyIj33sY3HhhRfGmDFbt1ZNTU3U1NSUMxoAAMCAsq7oVFdXx5QpU7b4YIH+/v5YtmxZTJs2bZvH/OUvf9kqZjKZTERElPk5CAAAADulrCs6ERFz5syJM844I4455pg47rjjYuHChbFhw4aYNWtWREScfvrpMXHixFiwYEFERMyYMSOuuuqqeOtb3xpTp06NRx99NC666KKYMWPGQPAAAADsTmWHzsyZM+PZZ5+Niy++OLq6umLy5MmxdOnSgQ8oWLt27RZXcObNmxdVVVUxb968+N3vfhf7779/zJgxI774xS/uvncBAADwMmV/j04l+B4dAAAgYpC+RwegEvL5iNbW0goAsDOEDjCs5fMRLS0RbW2lVewAADtD6ADDWkdHRCYTUSiU1s7OSk8EAIwEQgcY1pqaNkdOoRCRzVZ6IgBgJCj7U9cAhlIuF9HeXrqSk82WngMAvBKhAwx7uZzAAQDK49Y1AAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AG2kM9HtLaWVgCAkUroAAPy+YiWloi2ttIqdgCAkUroAAM6OiIymYhCobR2dlZ6IgCAXSN0gAFNTZsjp1CIyGYrPREAwK4ZW+kBgOEjl4toby9dyclmS88BAEYioQNsIZcTOADAyOfWNQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3SggvL5iNbW0goAwO4jdKBC8vmIlpaItrbSKnYAAHYfoQMV0tERkclEFAqltbOz0hMBAKRD6ECFNDVtjpxCISKbrfREAADpGFvpAWC0yuUi2ttLV3Ky2dJzAAB2D6EDFZTLCRwAgMHg1jUAACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QYdTI5yNaW0srAABpEzqMCvl8REtLRFtbaRU7AABpEzqMCh0dEZlMRKFQWjs7Kz0RAACDSegwKjQ1bY6cQiEim630RAAADKaxlR4AhkIuF9HeXrqSk82WngMAkC6hw6iRywkcAIDRwq1rAABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6DAo8vmI1tbSCgAAQ03osNvl8xEtLRFtbaVV7AAAMNSEDrtdR0dEJhNRKJTWzs5KTwQAwGgjdNjtmpo2R06hEJHNVnoiAABGm7GVHoD05HIR7e2lKznZbOk5AAAMJaHDoMjlBA4AAJXj1jUAACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QSUA+H9HaWloBAAChM+Ll8xEtLRFtbaVV7AAAgNAZ8To6IjKZiEKhtHZ2VnoiAACoPKEzwjU1bY6cQiEim630RAAAUHljKz0Ar04uF9HeXrqSk82WngMAwGgndBKQywkcAAB4ObeuAQAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJ2aXQWbRoUUyaNClqa2tj6tSpsWLFiu3um81mo6qqaqvHiSeeuMtDAwAA7EjZoXPbbbfFnDlzYv78+XH//ffH0UcfHdOnT49nnnlmm/vfcccd8fTTTw88HnzwwchkMvGP//iPr3p4AACAbSk7dK666qo4++yzY9asWfHmN785rrvuuthrr73ipptu2ub+r33ta2P8+PEDj3vuuSf22muvERs6+XxEa2tpBQAAhqeyQqevry9WrlwZzc3Nm3/AmDHR3Nwcy5cv36mfceONN8Ypp5wSr3nNa7a7z6ZNm6K3t3eLx3CQz0e0tES0tZVWsQMAAMNTWaGzfv36KBQK0dDQsMX2hoaG6OrqesXjV6xYEQ8++GCcddZZO9xvwYIFUV9fP/BobGwsZ8xB09ERkclEFAqltbOz0hMBAADbMqSfunbjjTfGUUcdFccdd9wO95s7d2709PQMPNatWzdEE+5YU9PmyCkUIrLZSk8EAABsy9hydh43blxkMpno7u7eYnt3d3eMHz9+h8du2LAhFi9eHJdccskrvk5NTU3U1NSUM9qQyOUi2ttLV3Ky2dJzAABg+Cnrik51dXVMmTIlli1bNrCtv78/li1bFtOmTdvhsd/5zndi06ZN8U//9E+7NukwkctFXHWVyAEAgOGsrCs6ERFz5syJM844I4455pg47rjjYuHChbFhw4aYNWtWREScfvrpMXHixFiwYMEWx914441x0kknxete97rdMzkAAMB2lB06M2fOjGeffTYuvvji6OrqismTJ8fSpUsHPqBg7dq1MWbMlheKVq9eHffdd1/86Ec/2j1TAwAA7EBVsVgsVnqIV9Lb2xv19fXR09MTdXV1lR4HAACokJ1tgyH91DUAAIChIHQAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIzi6FzqJFi2LSpElRW1sbU6dOjRUrVuxw/z/96U8xe/bsmDBhQtTU1MQb3/jGWLJkyS4NDAAA8ErGlnvAbbfdFnPmzInrrrsupk6dGgsXLozp06fH6tWr44ADDthq/76+vnjPe94TBxxwQHz3u9+NiRMnxpNPPhn77rvv7pgfAABgK1XFYrFYzgFTp06NY489Nq6++uqIiOjv74/GxsY477zz4oILLthq/+uuuy6uuOKKePjhh2OPPfbYpSF7e3ujvr4+enp6oq6ubpd+BgAAMPLtbBuUdetaX19frFy5Mpqbmzf/gDFjorm5OZYvX77NY/L5fEybNi1mz54dDQ0NceSRR8bll18ehUJhu6+zadOm6O3t3eIBAACws8oKnfXr10ehUIiGhoYttjc0NERXV9c2j1mzZk1897vfjUKhEEuWLImLLroo/u3f/i0uu+yy7b7OggULor6+fuDR2NhYzpgAAMAoN+ifutbf3x8HHHBAfO1rX4spU6bEzJkz48ILL4zrrrtuu8fMnTs3enp6Bh7r1q0b7DEBAICElPVhBOPGjYtMJhPd3d1bbO/u7o7x48dv85gJEybEHnvsEZlMZmDbm970pujq6oq+vr6orq7e6piampqoqakpZzQAAIABZV3Rqa6ujilTpsSyZcsGtvX398eyZcti2rRp2zzm7W9/ezz66KPR398/sO2RRx6JCRMmbDNyAAAAXq2yb12bM2dO3HDDDXHLLbfEQw89FOeee25s2LAhZs2aFRERp59+esydO3dg/3PPPTf++Mc/xqc+9al45JFH4q677orLL788Zs+evfveBQAAwMuU/T06M2fOjGeffTYuvvji6OrqismTJ8fSpUsHPqBg7dq1MWbM5n5qbGyMu+++O1pbW+Mtb3lLTJw4MT71qU/F5z73ud33LgAAAF6m7O/RqQTfowMAAEQM0vfoAAAAjARCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDm7FDqLFi2KSZMmRW1tbUydOjVWrFix3X1vvvnmqKqq2uJRW1u7ywMDAAC8krJD57bbbos5c+bE/Pnz4/7774+jjz46pk+fHs8888x2j6mrq4unn3564PHkk0++qqEBAAB2pOzQueqqq+Lss8+OWbNmxZvf/Oa47rrrYq+99oqbbrppu8dUVVXF+PHjBx4NDQ2vamgAAIAdKSt0+vr6YuXKldHc3Lz5B4wZE83NzbF8+fLtHvfnP/85DjrooGhsbIyWlpb4zW9+s8PX2bRpU/T29m7xAAAA2Fllhc769eujUChsdUWmoaEhurq6tnnM4YcfHjfddFO0t7fHN7/5zejv74/jjz8+nnrqqe2+zoIFC6K+vn7g0djYWM6YAADAKDfon7o2bdq0OP3002Py5Mnxrne9K+64447Yf//94/rrr9/uMXPnzo2enp6Bx7p16wZ7TAAAICFjy9l53Lhxkclkoru7e4vt3d3dMX78+J36GXvssUe89a1vjUcffXS7+9TU1ERNTU05owEAAAwo64pOdXV1TJkyJZYtWzawrb+/P5YtWxbTpk3bqZ9RKBTigQceiAkTJpQ3KQAAwE4q64pORMScOXPijDPOiGOOOSaOO+64WLhwYWzYsCFmzZoVERGnn356TJw4MRYsWBAREZdcckm87W1vi8MOOyz+9Kc/xRVXXBFPPvlknHXWWbv3nQAAAPx/ZYfOzJkz49lnn42LL744urq6YvLkybF06dKBDyhYu3ZtjBmz+ULR//3f/8XZZ58dXV1dsd9++8WUKVPiP//zP+PNb37z7nsXAAAAL1NVLBaLlR7ilfT29kZ9fX309PREXV1dpccBAAAqZGfbYNA/dQ0AAGCoCR0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAADYvnw+orW1tI4gQgcAANi2fD6ipSWira20jqDYEToAAMC2dXREZDIRhUJp7eys9EQ7TegAAADb1tS0OXIKhYhsttIT7bSxlR4AAAAYpnK5iPb20pWcbLb0fIQQOgAAwPblciMqcF7i1jUAACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAYLvL5iNbW0sqrInQAAGA4yOcjWloi2tpKq9h5VYQOAAAMBx0dEZlMRKFQWjs7Kz3RiCZ0AABgOGhq2hw5hUJENlvpiUa0sZUeAAAAiIhcLqK9vXQlJ5stPWeXCR0AABgucjmBs5u4dQ0AAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAIDRKZ+PaG0trSRH6AAAMPrk8xEtLRFtbaVV7CRH6AAAMPp0dERkMhGFQmnt7Kz0ROxmQgcAgNGnqWlz5BQKEdlspSdiNxtb6QEAAGDI5XIR7e2lKznZbOk5SRE6AACMTrmcwEmYW9cAAIDkCB0AACA5QgcAAEiO0AEAAJKzS6GzaNGimDRpUtTW1sbUqVNjxYoVO3Xc4sWLo6qqKk466aRdeVkAAICdUnbo3HbbbTFnzpyYP39+3H///XH00UfH9OnT45lnntnhcU888UR85jOfiXe+8527PCwAAMDOKDt0rrrqqjj77LNj1qxZ8eY3vzmuu+662GuvveKmm27a7jGFQiFOPfXU+Jd/+Zc45JBDXtXAAAAAr6Ss0Onr64uVK1dGc3Pz5h8wZkw0NzfH8uXLt3vcJZdcEgcccEB89KMf3anX2bRpU/T29m7xAAAA2Fllhc769eujUChEQ0PDFtsbGhqiq6trm8fcd999ceONN8YNN9yw06+zYMGCqK+vH3g0NjaWMyYAAMNNPh/R2lpaYQgM6qeuPffcc3HaaafFDTfcEOPGjdvp4+bOnRs9PT0Dj3Xr1g3ilAAADKp8PqKlJaKtrbSKHYbA2HJ2HjduXGQymeju7t5ie3d3d4wfP36r/R977LF44oknYsaMGQPb+vv7Sy88dmysXr06Dj300K2Oq6mpiZqamnJGAwBguOroiMhkIgqF0trZGZHLVXoqElfWFZ3q6uqYMmVKLFu2bGBbf39/LFu2LKZNm7bV/kcccUQ88MADsWrVqoFHLpeLpqamWLVqlVvSAABGg6amzZFTKERks5WeiFGgrCs6ERFz5syJM844I4455pg47rjjYuHChbFhw4aYNWtWREScfvrpMXHixFiwYEHU1tbGkUceucXx++67b0TEVtsBAEhULhfR3l66kpPNuprDkCg7dGbOnBnPPvtsXHzxxdHV1RWTJ0+OpUuXDnxAwdq1a2PMmEH91R8AAEaaXE7gMKSqisVisdJDvJLe3t6or6+Pnp6eqKurq/Q4AABAhexsG7j0AgAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJGVvpAXZGsViMiIje3t4KTwIAAFTSS03wUiNsz4gIneeeey4iIhobGys8CQAAMBw899xzUV9fv90/ryq+UgoNA/39/fH73/8+9tlnn6iqqqroLL29vdHY2Bjr1q2Lurq6is7CyOd8YndzTrE7OZ/YnZxP7C7FYjGee+65OPDAA2PMmO3/Js6IuKIzZsyYeP3rX1/pMbZQV1fnf6TsNs4ndjfnFLuT84ndyfnE7rCjKzkv8WEEAABAcoQOAACQHKFTppqampg/f37U1NRUehQS4Hxid3NOsTs5n9idnE8MtRHxYQQAAADlcEUHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0NmGRYsWxaRJk6K2tjamTp0aK1as2OH+3/nOd+KII46I2traOOqoo2LJkiVDNCkjQTnn0w033BDvfOc7Y7/99ov99tsvmpubX/H8Y/Qp959RL1m8eHFUVVXFSSedNLgDMqKUez796U9/itmzZ8eECROipqYm3vjGN/r3HgPKPZ8WLlwYhx9+eOy5557R2NgYra2tsXHjxiGaluQV2cLixYuL1dXVxZtuuqn4m9/8pnj22WcX991332J3d/c29//5z39ezGQyxS9/+cvF3/72t8V58+YV99hjj+IDDzwwxJMzHJV7Pn34wx8uLlq0qPjrX/+6+NBDDxXPPPPMYn19ffGpp54a4skZrso9p17y+OOPFydOnFh85zvfWWxpaRmaYRn2yj2fNm3aVDzmmGOKJ5xwQvG+++4rPv7448XOzs7iqlWrhnhyhqNyz6dbb721WFNTU7z11luLjz/+ePHuu+8uTpgwodja2jrEk5MqofNXjjvuuOLs2bMHnhcKheKBBx5YXLBgwTb3/+AHP1g88cQTt9g2derU4sc//vFBnZORodzz6a+9+OKLxX322ad4yy23DNaIjDC7ck69+OKLxeOPP7749a9/vXjGGWcIHQaUez5de+21xUMOOaTY19c3VCMygpR7Ps2ePbv47ne/e4ttc+bMKb797W8f1DkZPdy69jJ9fX2xcuXKaG5uHtg2ZsyYaG5ujuXLl2/zmOXLl2+xf0TE9OnTt7s/o8eunE9/7S9/+Uu88MIL8drXvnawxmQE2dVz6pJLLokDDjggPvrRjw7FmIwQu3I+5fP5mDZtWsyePTsaGhriyCOPjMsvvzwKhcJQjc0wtSvn0/HHHx8rV64cuL1tzZo1sWTJkjjhhBOGZGbSN7bSAwwn69evj0KhEA0NDVtsb2hoiIcffnibx3R1dW1z/66urkGbk5FhV86nv/a5z30uDjzwwK1imtFpV86p++67L2688cZYtWrVEEzISLIr59OaNWvixz/+cZx66qmxZMmSePTRR+Of//mf44UXXoj58+cPxdgMU7tyPn34wx+O9evXxzve8Y4oFovx4osvxjnnnBOf//znh2JkRgFXdGCY+tKXvhSLFy+O73//+1FbW1vpcRiBnnvuuTjttNPihhtuiHHjxlV6HBLQ398fBxxwQHzta1+LKVOmxMyZM+PCCy+M6667rtKjMQJ1dnbG5ZdfHtdcc03cf//9cccdd8Rdd90Vl156aaVHIxGu6LzMuHHjIpPJRHd39xbbu7u7Y/z48ds8Zvz48WXtz+ixK+fTS6688sr40pe+FPfee2+85S1vGcwxGUHKPacee+yxeOKJJ2LGjBkD2/r7+yMiYuzYsbF69eo49NBDB3dohq1d+WfUhAkTYo899ohMJjOw7U1velN0dXVFX19fVFdXD+rMDF+7cj5ddNFFcdppp8VZZ50VERFHHXVUbNiwIT72sY/FhRdeGGPG+O/xvDrOoJeprq6OKVOmxLJlywa29ff3x7Jly2LatGnbPGbatGlb7B8Rcc8992x3f0aPXTmfIiK+/OUvx6WXXhpLly6NY445ZihGZYQo95w64ogj4oEHHohVq1YNPHK5XDQ1NcWqVauisbFxKMdnmNmVf0a9/e1vj0cffXQgmCMiHnnkkZgwYYLIGeV25Xz6y1/+slXMvBTRxWJx8IZl9Kj0pyEMN4sXLy7W1NQUb7755uJvf/vb4sc+9rHivvvuW+zq6ioWi8XiaaedVrzgggsG9v/5z39eHDt2bPHKK68sPvTQQ8X58+f7eGkGlHs+felLXypWV1cXv/vd7xaffvrpgcdzzz1XqbfAMFPuOfXXfOoaL1fu+bR27driPvvsU/zEJz5RXL16dfE//uM/igcccEDxsssuq9RbYBgp93yaP39+cZ999il++9vfLq5Zs6b4ox/9qHjooYcWP/jBD1bqLZAYt679lZkzZ8azzz4bF198cXR1dcXkyZNj6dKlA79ct3bt2i3+68Pxxx8f3/rWt2LevHnx+c9/Pt7whjfEnXfeGUceeWSl3gLDSLnn07XXXht9fX3xgQ98YIufM3/+/PjCF74wlKMzTJV7TsGOlHs+NTY2xt133x2tra3xlre8JSZOnBif+tSn4nOf+1yl3gLDSLnn07x586KqqirmzZsXv/vd72L//fePGTNmxBe/+MVKvQUSU1UsujYIAACkxX/2AwAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDn/D+PFE2SrytQ0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## one way to measure how wrong or poor your models predictions are is to use the loss function\n",
        "## they may call it the cost function or creitreian in differents areas\n",
        "## OPTIMIZER :takes into acount the loss of a model and adjust the model parameters ( a and b in this eg) to imporove the loss function\n",
        "## and specifcally for pytorch we need a\n",
        "## TESTING LOOP\n",
        "## TRAINIG LOOP\n"
      ],
      "metadata": {
        "id": "KJOJF7DRlgKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SETUP A LOSS FUNCTION\n",
        "loss_fn = nn.L1Loss()\n",
        "## setup un optimizer SGD\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
        "                            lr = 0.01 )## lr stand for learning rate possibly the most important hyperparamters you can set"
      ],
      "metadata": {
        "id": "Hm9zXV98n-oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## an epoch is one loop through the data\n",
        "torch.manual_seed(42)\n",
        "epochs = 1000\n",
        "## loop through the data\n",
        "for epoch in range(epochs):\n",
        "  ## set the model to the training mode\n",
        "  model_0.train() ##train mode in pytorch sets all parameters that requires gradiants to requirers gradients\n",
        "   ### turn of the gradiants traking\n",
        "  ###1 forward pass\n",
        "  y_pred = model_0(x_train)\n",
        "  ## 2 calculate the loss\n",
        "  loss = loss_fn(y_pred,y_train)\n",
        "  print(\"the loss is \",loss)\n",
        "\n",
        "  ##3 optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "  ##4 performe backpropagation on the loss with respect to the paramters of the model\n",
        "  loss.backward()\n",
        "  ## 5 set the optimzer\n",
        "  optimizer.step()\n",
        "\n",
        "  ## TESTING\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_preds = model_0(x_test)\n",
        "    test_loss = loss_fn(test_preds , y_test)\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch  : {epoch} | loos : {loss} |test_loss {test_loss} \")\n",
        "    print(model_0.state_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTl35zrnn-lz",
        "outputId": "9465262e-3ab8-4ad9-a0d2-f80871b0736c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the loss is  tensor(0.5574, grad_fn=<MeanBackward0>)\n",
            "epoch  : 0 | loos : 0.557431697845459 |test_loss 0.5258052945137024 \n",
            "OrderedDict([('a', tensor([0.3404])), ('b', tensor([0.1388]))])\n",
            "the loss is  tensor(0.5460, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.5346, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.5118, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.4890, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.4776, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.4662, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.4548, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.4434, grad_fn=<MeanBackward0>)\n",
            "epoch  : 10 | loos : 0.44336917996406555 |test_loss 0.3929927349090576 \n",
            "OrderedDict([('a', tensor([0.3779])), ('b', tensor([0.2388]))])\n",
            "the loss is  tensor(0.4320, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.4206, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.4092, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3977, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3863, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3749, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3635, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3521, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3407, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3293, grad_fn=<MeanBackward0>)\n",
            "epoch  : 20 | loos : 0.3293067216873169 |test_loss 0.26018035411834717 \n",
            "OrderedDict([('a', tensor([0.4154])), ('b', tensor([0.3388]))])\n",
            "the loss is  tensor(0.3179, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.3065, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2951, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2837, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2723, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2609, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2495, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2381, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2267, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.2152, grad_fn=<MeanBackward0>)\n",
            "epoch  : 30 | loos : 0.2152443379163742 |test_loss 0.1273679882287979 \n",
            "OrderedDict([('a', tensor([0.4529])), ('b', tensor([0.4388]))])\n",
            "the loss is  tensor(0.2038, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1924, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1810, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1696, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1582, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1468, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1354, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1240, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1126, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.1012, grad_fn=<MeanBackward0>)\n",
            "epoch  : 40 | loos : 0.10118190944194794 |test_loss 0.009863719344139099 \n",
            "OrderedDict([('a', tensor([0.4904])), ('b', tensor([0.5388]))])\n",
            "the loss is  tensor(0.0898, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0784, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0679, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0604, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0553, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0517, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0492, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0472, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0457, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0444, grad_fn=<MeanBackward0>)\n",
            "epoch  : 50 | loos : 0.04441704973578453 |test_loss 0.07893653213977814 \n",
            "OrderedDict([('a', tensor([0.5030])), ('b', tensor([0.6013]))])\n",
            "the loss is  tensor(0.0437, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0430, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0423, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0416, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0410, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0406, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0402, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0398, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0394, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0391, grad_fn=<MeanBackward0>)\n",
            "epoch  : 60 | loos : 0.03906793147325516 |test_loss 0.08528037369251251 \n",
            "OrderedDict([('a', tensor([0.4903])), ('b', tensor([0.6188]))])\n",
            "the loss is  tensor(0.0387, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0383, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0379, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0375, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0372, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0368, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0364, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0357, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0353, grad_fn=<MeanBackward0>)\n",
            "epoch  : 70 | loos : 0.03533663973212242 |test_loss 0.08296801149845123 \n",
            "OrderedDict([('a', tensor([0.4748])), ('b', tensor([0.6301]))])\n",
            "the loss is  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0347, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
            "epoch  : 80 | loos : 0.031850457191467285 |test_loss 0.07390560209751129 \n",
            "OrderedDict([('a', tensor([0.4573])), ('b', tensor([0.6363]))])\n",
            "the loss is  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0302, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0298, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0295, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0291, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0288, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0284, grad_fn=<MeanBackward0>)\n",
            "epoch  : 90 | loos : 0.028442833572626114 |test_loss 0.06653071939945221 \n",
            "OrderedDict([('a', tensor([0.4403])), ('b', tensor([0.6438]))])\n",
            "the loss is  tensor(0.0281, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0278, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0274, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0271, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0267, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0264, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0260, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0257, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0253, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0250, grad_fn=<MeanBackward0>)\n",
            "epoch  : 100 | loos : 0.02495529130101204 |test_loss 0.05915580689907074 \n",
            "OrderedDict([('a', tensor([0.4233])), ('b', tensor([0.6513]))])\n",
            "the loss is  tensor(0.0247, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0236, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0233, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0229, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0226, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0222, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0219, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0215, grad_fn=<MeanBackward0>)\n",
            "epoch  : 110 | loos : 0.02154901996254921 |test_loss 0.0500933974981308 \n",
            "OrderedDict([('a', tensor([0.4058])), ('b', tensor([0.6576]))])\n",
            "the loss is  tensor(0.0212, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0209, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0205, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0202, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0198, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0195, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0191, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0188, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0184, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0181, grad_fn=<MeanBackward0>)\n",
            "epoch  : 120 | loos : 0.018061481416225433 |test_loss 0.04271849989891052 \n",
            "OrderedDict([('a', tensor([0.3888])), ('b', tensor([0.6651]))])\n",
            "the loss is  tensor(0.0178, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0174, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0171, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0167, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0164, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0160, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0157, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0153, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0150, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0147, grad_fn=<MeanBackward0>)\n",
            "epoch  : 130 | loos : 0.014650382101535797 |test_loss 0.03365606069564819 \n",
            "OrderedDict([('a', tensor([0.3713])), ('b', tensor([0.6713]))])\n",
            "the loss is  tensor(0.0143, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0140, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0136, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0133, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0129, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0126, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0122, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0119, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0115, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0112, grad_fn=<MeanBackward0>)\n",
            "epoch  : 140 | loos : 0.011167675256729126 |test_loss 0.026281192898750305 \n",
            "OrderedDict([('a', tensor([0.3543])), ('b', tensor([0.6788]))])\n",
            "the loss is  tensor(0.0109, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0105, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0102, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0098, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0095, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0091, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0088, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0084, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0081, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0078, grad_fn=<MeanBackward0>)\n",
            "epoch  : 150 | loos : 0.00775035098195076 |test_loss 0.017218738794326782 \n",
            "OrderedDict([('a', tensor([0.3368])), ('b', tensor([0.6851]))])\n",
            "the loss is  tensor(0.0074, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0071, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0067, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0064, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0060, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0057, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0053, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0050, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0047, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0043, grad_fn=<MeanBackward0>)\n",
            "epoch  : 160 | loos : 0.004273861646652222 |test_loss 0.009843841195106506 \n",
            "OrderedDict([('a', tensor([0.3198])), ('b', tensor([0.6926]))])\n",
            "the loss is  tensor(0.0040, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0036, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0033, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0029, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0026, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0022, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0022, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 170 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 180 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 190 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 200 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 210 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 220 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 230 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 240 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 250 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 260 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 270 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 280 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 290 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 300 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 310 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 320 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 330 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 340 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 350 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 360 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 370 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 380 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 390 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 400 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 410 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 420 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 430 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 440 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 450 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 460 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 470 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 480 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 490 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 500 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 510 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 520 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 530 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 540 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 550 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 560 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 570 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 580 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 590 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 600 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 610 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 620 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 630 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 640 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 650 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 660 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 670 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 680 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 690 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 700 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 710 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 720 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 730 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 740 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 750 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 760 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 770 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 780 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 790 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 800 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 810 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 820 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 830 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 840 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 850 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 860 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 870 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 880 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 890 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 900 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 910 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 920 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 930 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 940 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 950 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 960 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 970 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 980 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "epoch  : 990 | loos : 0.003680385649204254 |test_loss 0.012945398688316345 \n",
            "OrderedDict([('a', tensor([0.3104])), ('b', tensor([0.7038]))])\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0037, grad_fn=<MeanBackward0>)\n",
            "the loss is  tensor(0.0077, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions = y_preds)"
      ],
      "metadata": {
        "id": "L804EyLPn-kC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "b14eed1f-f4e1-47c4-f484-b0c88224abc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred_new = model_0(x_test)\n",
        "y_pred_new"
      ],
      "metadata": {
        "id": "FILGCpvbn-iC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b838a6e-610c-441d-a3c0-d11f905a099c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9392],\n",
              "        [0.9545],\n",
              "        [0.9698],\n",
              "        [0.9852]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions = y_pred_new)"
      ],
      "metadata": {
        "id": "mtOBJm9rn-fr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "0f95e562-3321-4948-c1f2-08d628f11c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PkBIYO1Jha96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### saving the model that we had\n",
        "from  pathlib import Path\n",
        "#1\\ FIRST THING CREAT YOUR MODEL DIRECTORY\n",
        "MODEL_PATH = Path(model)\n",
        "MODEL_PATH.mkdir(parents = True ,exsit = True )\n",
        "\n",
        "## 2\\create the model  and save the path\n",
        "MODEL_NAME = 'linearRM.pth'\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "###3\\ SAVE THE MODEL THAT WE HAD\n",
        "torch.save(obj = model_0.sate_dict(),f = MODEL_SAVE_PATH)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "aLhntzu4ha1U",
        "outputId": "46b0dc14-b9f0-4281-a0a5-b858552aa67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a0def7e26c4b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m  \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#1\\ FIRST THING CREAT YOUR MODEL DIRECTORY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mexsit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# 1. Create your model directory\n",
        "MODEL_PATH = Path('models')  # Corrected from 'path' to 'Path'\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)  # Corrected 'exsit' to 'exist'\n",
        "\n",
        "# 2. Define the model name and save path\n",
        "MODEL_NAME = 'linearRM.pth'\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dictionary\n",
        "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "ohHDZ1Sbhaxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x5VHCeBRhavL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### laod the model\n",
        "##1\\ create a new instance of the same class that  we had\n",
        "model_loaded = LinearRegressionM()\n",
        "##2\\ load the state dict\n",
        "model_loaded.load_state_dict(torch.load(MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "id": "VFi7B38dkvp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.state_dict()"
      ],
      "metadata": {
        "id": "7T3Ps7LWhatE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "de2cc4ea-0ab4-4a6b-b42a-8085f4f6902a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_loaded' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-87eef4e86513>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_loaded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EXd0rpPn-dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RoosDi8Ln-a-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}